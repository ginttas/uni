2022-09-20\
Kaunas\
ML Fundamentals

----

3 Fundamentals of supervised ML
* Trading data
* Const|Loss|Error function
* ML model
* Training algorithm

----

Generalization
* The goal of the model is to generize well for the unssen data
* Undefiting = Overgeneralization
* Overfiting = Undergeneralization

Bias vs variance tradeof

Improving error function (Penalty for large weights)

Train test split

k-flod cross valdiation, helpts to minimize anomaly impact in your testing and training data

Validation is not testing, we use validation to tune our model, testing is just for testing

After testing we shouldn't change our model any more

Occam's Razor (Shave off whats unnesicary)\
Entities should not be multiplied without necessity\
Everything should be made as simple as possible, but not simpler

----

Supervised ML methods
* Decision trees
    * Random forest
    * Ada boost
    * ...
* knn
* Linear models (min MSE)
    * Nonlinear Expansion
    * Suport vector mashines
    * Radial basis function
    * Kernel methods
        * Infinite dimensions
        * Kernel trick
    * ...
* Graphical ML models
    * Bayesian network


----

Joint probability density?
